{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from ngram import generate_ngram_models\n",
    "from ngram import calculate_smoothed_probability\n",
    "from nltk.corpus import reuters\n",
    "from tqdm import tqdm\n",
    "from edit_distance import CandidatesGenerator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T11:51:59.654758Z",
     "start_time": "2024-06-03T11:51:58.736766Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 读取字典库、语料库"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vocab = {line.rstrip() for line in open('vocab.txt')}\n",
    "#用set来存储不用list是因为查找的时候set时间复杂度是O(1),List是O(n)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T11:51:59.685107Z",
     "start_time": "2024-06-03T11:51:59.657183Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\komusama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\komusama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('reuters')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T11:52:07.241055Z",
     "start_time": "2024-06-03T11:51:59.686104Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 据语料库生成ngram模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "categories = reuters.categories()  # 路透社语料库的类别\n",
    "corpus = reuters.sents(categories=categories)  # sents()指定分类中的句子\n",
    "\n",
    "# 构建语言模型：bigram\n",
    "term_count, bigram_count=generate_ngram_models(corpus,2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T11:52:15.550200Z",
     "start_time": "2024-06-03T11:52:07.243035Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 从count_1edit.txt获取channel probability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 用户打错的概率统计 - channel probability\n",
    "# 创建一个字典来存储channel probabilities\n",
    "channel_prob = {}\n",
    "total_errors = 0\n",
    "\n",
    "i = 0\n",
    "# 解析错误数据并计算总错误次数\n",
    "for line in open('count_1edit.txt'):\n",
    "    i += 1\n",
    "    # Step1:解析数据\n",
    "    # 正则表达式找到错误次数\n",
    "    count = re.findall(r'\\d+', line)[-1]\n",
    "    \n",
    "    # 从末尾剥离数字\n",
    "    line = line.replace(count, \"\")\n",
    "    # 剥离制表符\n",
    "    if \"\\t\" in line:\n",
    "        line = line.replace(\"\\t\", \"\")\n",
    "    # 判断空格在不在后段\n",
    "    first, last = line.split(\"|\")\n",
    "\n",
    "    if \" \" in last:\n",
    "        # 去除多个空格为一个    \n",
    "        if re.match(r\" {2,}\", line):\n",
    "            multi_spaces = re.findall(r\" {2,}\", line)\n",
    "            for space in multi_spaces:\n",
    "                line = line.replace(space, \" \")\n",
    "    \n",
    "    # 正常情况\n",
    "    correct, mistake = line.split(\"|\")\n",
    "\n",
    "    count = int(count)\n",
    "    # Step2:计算错误次数\n",
    "    if correct not in channel_prob:\n",
    "        channel_prob[correct] = {}\n",
    "\n",
    "    channel_prob[correct][mistake] = count\n",
    "    total_errors += count\n",
    "\n",
    "# 计算每种错误的概率\n",
    "for correct in channel_prob:\n",
    "    for mistake in channel_prob[correct]:\n",
    "        channel_prob[correct][mistake] /= total_errors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T11:52:15.566042Z",
     "start_time": "2024-06-03T11:52:15.553076Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 测试"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 创建生成者\n",
    "CG = CandidatesGenerator(vocab=vocab)\n",
    "# 设置最大编辑距离\n",
    "max_distance = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T11:52:15.582033Z",
     "start_time": "2024-06-03T11:52:15.567039Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines: 100%|██████████| 1000/1000 [00:00<00:00, 3665.57it/s]\n"
     ]
    }
   ],
   "source": [
    "def count_lines(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return sum(1 for line in f)\n",
    "\n",
    "# 计算文件的行数\n",
    "file_path = \"testdata.txt\"\n",
    "total_lines = count_lines(file_path)\n",
    "V = len(term_count.keys())\n",
    "# 打开文件\n",
    "with open(file_path, \"r\") as file:\n",
    "    results = []\n",
    "    i = 1\n",
    "    bar = tqdm(file, total=total_lines, desc=\"Processing lines\")\n",
    "    # 开始测试\n",
    "    for line in bar:\n",
    "        line = re.sub(r\"([,])([^\\d])\", r\" \\1 \\2\", line)\n",
    "        \n",
    "        line = re.sub(r\"([^s])(['])\", r\"\\1 \\2\", line)\n",
    "        line = re.sub(r\"([s])(['])\", r\"\\1 \\2 \", line)\n",
    "\n",
    "        line = re.sub(r\"([.]$)\", r\" \\1 \", line)\n",
    "        # items = line.rstrip().split(\"\\t\")\n",
    "        items = line.split(\"\\t\")\n",
    "        line = items[2].split()\n",
    "        corrected_line = line\n",
    "        j = 0\n",
    "        # 遍历句子单词\n",
    "        for word in line:\n",
    "            if word not in vocab:\n",
    "                # 需要替换word成正确的单词\n",
    "                # Step1: 生成所有的(valid)候选集合\n",
    "                # 获得编辑距离小于2的候选列表\n",
    "                candidates = CG.generate_candidates(word,max_distance=max_distance)\n",
    "                candidates = list(candidates)\n",
    "                probs = []\n",
    "                \n",
    "                # 对于每一个candidate, 计算它的score\n",
    "                # score = p(correct)*p(mistake|correct)\n",
    "                #       = log p(correct) + log p(mistake|correct)\n",
    "                # 返回score最大的candidate\n",
    "                for candi in candidates:\n",
    "                    prob = 0\n",
    "                    # 计算channel probability\n",
    "                    if candi in channel_prob and word in channel_prob[candi]:\n",
    "                        prob += np.log(channel_prob[candi][word])\n",
    "                    else:\n",
    "                        prob += np.log(0.0001)\n",
    "                    \n",
    "                    # 计算语言模型的概率\n",
    "                    # 以s=I like playing football.为例line=['I','like','playing','football']\n",
    "                    # word为playing时\n",
    "                    if j>0:\n",
    "                        forward_word = line[j - 1] + \" \" + candi  # 考虑前一个单词,出现like playing的概率\n",
    "                        prob += calculate_smoothed_probability(bigram_count,term_count,V,forward_word,line[j - 1])\n",
    "                    if j + 1 < len(line):  \n",
    "                        backward_word = candi + \" \" + line[j + 1] # 考虑后一个单词，出现playing football的概率\n",
    "                        prob += calculate_smoothed_probability(bigram_count,term_count,V,backward_word,candi)\n",
    "                    probs.append(prob)\n",
    "\n",
    "                if probs:\n",
    "                    max_idx = probs.index(max(probs))\n",
    "                    if len(word) == 1:\n",
    "                        corrected_line[j] = word  # 不替换单个字母\n",
    "                    else:\n",
    "                        corrected_line[j] = candidates[max_idx]\n",
    "            j += 1\n",
    "\n",
    "        corrected_sentence = \" \".join(corrected_line)\n",
    "        corrected_sentence = re.sub(r\"\\s*(['])\\s*\", r\"\\1\", corrected_sentence)  # 去除标点前的空格\n",
    "        corrected_sentence = re.sub(r\"(s')\", r\"\\1 \", corrected_sentence)  # 恢复s'的情况\n",
    "\n",
    "\n",
    "        corrected_sentence = re.sub(r\"\\s([.])\\s\", r\"\\1\", corrected_sentence)  # 去除标点前的空格\n",
    "\n",
    "        corrected_sentence = re.sub(r\"\\s([,])\", r\"\\1\", corrected_sentence)  # 去除标点前的空格（保留逗号后面的空格）\n",
    "        corrected_sentence = re.sub(r\"(\\d)([,])\\s+(\\d)\", r\"\\1\\2\\3\", corrected_sentence)  # 去除数据中的空格\n",
    "        # 句点补全\n",
    "        if corrected_sentence[-1] != \".\":\n",
    "            corrected_sentence += \".\"\n",
    "        \n",
    "        results.append(f\"{i}\\t{corrected_sentence}\")\n",
    "        i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T11:55:04.196571Z",
     "start_time": "2024-06-03T11:55:03.895833Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"result.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(results))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T11:55:04.211531Z",
     "start_time": "2024-06-03T11:55:04.197563Z"
    }
   },
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 直接调用测试"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"python eval.py\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T11:55:05.203883Z",
     "start_time": "2024-06-03T11:55:05.104636Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
